{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation\n",
    "\n",
    "### Input:\n",
    "##### 1) CSV of Targets for each image\n",
    "##### 2) All folders of train images from Kaggle in a new folder called train in a local only SML_Project_Data folder (38.1 GB total). The SML_Project_Data folder is in the same folder as the GitHub folder of DS-5220-Supervised-Machine-Learning-Project\n",
    "### Output:\n",
    "##### High level directory called data is created. Inside of high level folder are two major directories of train and val. Each major director has a seperate folder for each of the 5 classes. This results in 10 folders with resized images in them.\n",
    "### Next Steps:\n",
    "##### Move high level directory and all contents next to script which will train model. The script which trains the model can create all of the folders, even though they would be empty of course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Notes\n",
    "- Classes are very unballanced with most being class 0. This must be solved before upload to system which trains model.\n",
    "- The Test data has no labels, so we should use the training data to evaluate the models\n",
    "- Each eye from a unique person has images next to each other in the training set\n",
    "- The JPEG are compressed versus RGB matrices, so they are smaller than those tensors by a factor of 15 even with the same information in the JPEG and array.\n",
    "# Possible Deep Learning Classification Improvements\n",
    "- Each eye can have a different disease value. However, there is strong correlation of the disease one eye to other eye\n",
    "- Images are different sizes, but it is easy to rescale all images to a set size. Other sizes can be tried, such as larger sizes more similar to the original images.\n",
    "- Deal with use of notch on reversed eye images.\n",
    "- Images have color, but not too much. Can try to convert to greyscale to reduce the bytes of the image which results in more room to have a larger image with more pixels. Note, this will require changing the model because it expects a size of (x, y, 3) of each of Red Green and Blue.\n",
    "- The CNN architecture was for 150 by 150 color dog and cat images. The 500 by 500 eye images may need a different architecture. In particular, other filter windows may be important. Since the image is larger, more convolution layers may be needed.\n",
    "- Data augmentation on non-0 class\n",
    "- Remove black outer edge in images\n",
    "- Use of existing image models for transfer learning like VGG16-VGG19\n",
    "# Sick/Healthy Model\n",
    "- If we use different format of the data, such as using a sick/healthy class this is done by changing the final layer of the CNN model as well as the Keras DirectoryIterator. This can be done by making sure that there are two folders inside of the train and val subfolder.\n",
    "# Notes of Manual Steps\n",
    "- Ballancing the classes. Manually moved a set number of files from each class into a train and validate folder. This should be able to be automated, when it could be done most easily if there is an object of the name of all objects in a folder.\n",
    "- Moving images into the proper folders of Google Colab. This took around 40 minutes for the 500 x 500 images.\n",
    "# Suggested Next Steps before Preliminary Report\n",
    "- 0) **Must Complete Before Preliminary Report:** Carry out more detailed analysis of results, such as where there is confusion, and the level of the errors\n",
    "- 1) Try simplier models such as logistic classification or an ensemble method. Can try more diverse data resizing (such as only making the images the same size), and pre-processing tecniques before further training in neural networks. Would not suggest creating features of textures since that is automatically done in deep learning, so we would not be able to transfer that over.\n",
    "- 2) Split apart validation and test set to allow more easy comparison with simplier models. Can combine part of the validation set with the training set if cross validation or no distinct validation set is being used. Would suggest 10% on the test set, since currently it is 20% validation set.\n",
    "- 3) Get automated way to place resized images in desired train or validate folders to speed up testing process of any models.\n",
    "- 4) Try data augmentation on the non class 0 images. Must keep validation images unchanged though.\n",
    "- 5) Try other architectures of the CNN model to match larger tensors, and use of classification using eye images instead of a binary cats versus dogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of a Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3168, 4752, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load an color image in color\n",
    "img = cv2.imread('../SML_Project_Data/train/10_left.jpeg',1)\n",
    "print(img.shape)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create PNG of Image Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('10_left_new.jpeg',img) # Confirmed manually the exported image is the same number of bytes as the original image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Image Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3168, 4752, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[1500][2300][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Size (3168, 4752, 3)\n",
      "45163008 bytes in original image\n",
      "MB in the original array image is 45.163008 versus the original image JPEG has 1.5 MB\n",
      "Resized Size (100, 100, 3)\n",
      "30000 bytes in compressed image\n",
      "Original pixel size is 45163008\n",
      "New pixel size is 30000\n",
      "Factor of reduction is by 1505.4336\n"
     ]
    }
   ],
   "source": [
    "print('Original Size', img.shape)\n",
    "\n",
    "print(\"%d bytes in original image\" % (img.size * img.itemsize))\n",
    "\n",
    "print('MB in the original array image is', img.size * img.itemsize / 1000000, 'versus the original image JPEG has 1.5 MB') # 1 million bytes in a MB\n",
    "\n",
    "resized = cv2.resize(img, (100, 100), interpolation = cv2.INTER_AREA)\n",
    "print('Resized Size', resized.shape)\n",
    "cv2.imwrite('10_left_reshaped_new.jpeg',resized) # Goes from 1.5 MB to 3 KB which redices the size by a factor 1 K\n",
    "\n",
    "print(\"%d bytes in compressed image\" % (resized.size * resized.itemsize))\n",
    "\n",
    "print('Original pixel size is', np.prod(img.shape))\n",
    "print('New pixel size is', np.prod(resized.shape))\n",
    "print('Factor of reduction is by', np.prod(img.shape) / np.prod(resized.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downscale Images to 100 x 100 x 3 and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35126\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image  level\n",
       "0   10_left      0\n",
       "1  10_right      0\n",
       "2   13_left      0\n",
       "3  13_right      0\n",
       "4   15_left      1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target = pd.read_csv('../SML_Project_Data/trainLabels.csv', delimiter=',')\n",
    "print(len(train_target))\n",
    "train_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35126"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_images = 0\n",
    "for index, row in train_target.iterrows():\n",
    "    split_image = row['image'].split('_')\n",
    "    image_num = split_image[0]\n",
    "    side = split_image[1]\n",
    "    \n",
    "    image_name = str(image_num) + '_' + side + '.jpeg'\n",
    "\n",
    "    train_image_path = '../SML_Project_Data/train/' + image_name\n",
    "\n",
    "    my_file = Path(train_image_path)\n",
    "\n",
    "    try:\n",
    "        my_abs_path = my_file.resolve(strict=True)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    else:\n",
    "        total_images = total_images + 1\n",
    "total_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsizes all images and moves to subfolders in the main Data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Folder Already Exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create folders for each\n",
    "try:\n",
    "    os.mkdir('../SML_Project_Data/data')\n",
    "except FileExistsError:\n",
    "    print('Data Folder Already Exists \\n')\n",
    "else:\n",
    "    print('Creating Data Folder \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking to create folder of ../SML_Project_Data/data/resized_0\n",
      "Folder Already Exists \n",
      "\n",
      "Looking to create folder of ../SML_Project_Data/data/resized_1\n",
      "Folder Already Exists \n",
      "\n",
      "Looking to create folder of ../SML_Project_Data/data/resized_2\n",
      "Folder Already Exists \n",
      "\n",
      "Looking to create folder of ../SML_Project_Data/data/resized_3\n",
      "Folder Already Exists \n",
      "\n",
      "Looking to create folder of ../SML_Project_Data/data/resized_4\n",
      "Folder Already Exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for disease in (0, 1, 2, 3, 4):\n",
    "    path = '../SML_Project_Data/data/resized_' + str(disease)\n",
    "    print('Looking to create folder of', path)\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except FileExistsError:\n",
    "        print('Folder Already Exists \\n')\n",
    "    else:\n",
    "        print('Creating Folder \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will give a status every 1756 images\n",
      "At 1756 images out of 35126\n",
      "At 3512 images out of 35126\n",
      "At 5268 images out of 35126\n",
      "At 7024 images out of 35126\n",
      "At 8780 images out of 35126\n",
      "At 10536 images out of 35126\n",
      "At 12292 images out of 35126\n",
      "At 14048 images out of 35126\n",
      "At 15804 images out of 35126\n",
      "At 17560 images out of 35126\n",
      "At 19316 images out of 35126\n",
      "At 21072 images out of 35126\n",
      "At 22828 images out of 35126\n",
      "At 24584 images out of 35126\n",
      "At 26340 images out of 35126\n",
      "At 28096 images out of 35126\n",
      "At 29852 images out of 35126\n",
      "At 31608 images out of 35126\n",
      "At 33364 images out of 35126\n",
      "At 35120 images out of 35126\n",
      "Processed Imnage Count 35126\n"
     ]
    }
   ],
   "source": [
    "# Distribute Images to each Folder\n",
    "counter = 0\n",
    "\n",
    "status = int(total_images / 20)\n",
    "print('Will give a status every', status, 'images')\n",
    "\n",
    "new_shape = (500, 500)\n",
    "\n",
    "for index, row in train_target.iterrows():\n",
    "    #print(row['image'], row['level'])\n",
    "    \n",
    "    split_image = row['image'].split('_')\n",
    "    image_num = split_image[0]\n",
    "    side = split_image[1]\n",
    "\n",
    "    image_name = str(image_num) + '_' + side + '.jpeg'\n",
    "\n",
    "    train_image_path = '../SML_Project_Data/train/' + image_name\n",
    "\n",
    "    my_file = Path(train_image_path)\n",
    "\n",
    "    try:\n",
    "        my_abs_path = my_file.resolve(strict=True)\n",
    "    except FileNotFoundError:\n",
    "        print('File not found')\n",
    "        pass\n",
    "    else:\n",
    "        counter = counter + 1\n",
    "        \n",
    "        # Pull Image\n",
    "        img2 = cv2.imread(train_image_path, 1)\n",
    "        # Resize\n",
    "        resized = cv2.resize(img2, new_shape, interpolation = cv2.INTER_AREA)\n",
    "        # Create New Image File\n",
    "        path = '../SML_Project_Data/data/resized_' + str(row['level']) + '/' + image_name\n",
    "        #print('Path:', path)\n",
    "        cv2.imwrite(path, resized)\n",
    "        resized\n",
    "    if counter % status == 0:\n",
    "        print('At', counter, 'images out of', total_images)\n",
    "        \n",
    "print('Processed Imnage Count', counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease Class of 0 has count of images of 25810\n",
      "Disease Class of 1 has count of images of 2443\n",
      "Disease Class of 2 has count of images of 5292\n",
      "Disease Class of 3 has count of images of 873\n",
      "Disease Class of 4 has count of images of 708\n",
      "Mininum count by class is 708\n",
      "Training set will have 566\n",
      "Validation/Test set will have 142\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os, shutil\n",
    "\n",
    "min_file_count = np.inf\n",
    "for disease_type in (0, 1, 2, 3, 4):\n",
    "    path, dirs, files = next(os.walk('../SML_Project_Data/data/resized_' + str(disease_type)))\n",
    "    file_count = len(files)\n",
    "    if file_count < min_file_count:\n",
    "        min_file_count = file_count\n",
    "    print('Disease Class of', disease_type, 'has count of images of', file_count)\n",
    "print('Mininum count by class is', min_file_count)\n",
    "    \n",
    "train_file_count = int(min_file_count * .80)\n",
    "print('Training set will have', train_file_count)\n",
    "val_file_count = min_file_count - train_file_count\n",
    "print('Validation/Test set will have', val_file_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and/or Val Folder Already Exists \n",
      "\n",
      "Looking to create folder of ../SML_Project_Data/data/resized_0\n",
      "Train and/or Val Folder Already Exists \n",
      "\n",
      "Looking to create folder of ../SML_Project_Data/data/resized_1\n",
      "Train and/or Val Folder Already Exists \n",
      "\n",
      "Looking to create folder of ../SML_Project_Data/data/resized_2\n",
      "Looking to create folder of ../SML_Project_Data/data/resized_3\n",
      "Looking to create folder of ../SML_Project_Data/data/resized_4\n",
      "Looking to create folder of ../SML_Project_Data/data/resized_0\n",
      "Train and/or Val Folder Already Exists \n",
      "\n",
      "Looking to create folder of ../SML_Project_Data/data/resized_1\n",
      "Train and/or Val Folder Already Exists \n",
      "\n",
      "Looking to create folder of ../SML_Project_Data/data/resized_2\n",
      "Train and/or Val Folder Already Exists \n",
      "\n",
      "Looking to create folder of ../SML_Project_Data/data/resized_3\n",
      "Train and/or Val Folder Already Exists \n",
      "\n",
      "Looking to create folder of ../SML_Project_Data/data/resized_4\n",
      "Train and/or Val Folder Already Exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir('../SML_Project_Data/data/train')\n",
    "    os.mkdir('../SML_Project_Data/data/val')\n",
    "except FileExistsError:\n",
    "    print('Train and/or Val Folder Already Exists \\n')\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# Create Training Set\n",
    "for disease in (0, 1, 2, 3, 4):\n",
    "    path = '../SML_Project_Data/data/resized_' + str(disease)\n",
    "    \n",
    "    train_path = '../SML_Project_Data/data/train/resized_' + str(disease)\n",
    "    \n",
    "    val_path = '../SML_Project_Data/data/val/resized_' + str(disease)\n",
    "    \n",
    "    print('Looking to create folder of', path)\n",
    "    try:\n",
    "        os.mkdir(train_path)\n",
    "        os.mkdir(val_path)\n",
    "    except FileExistsError:\n",
    "        print('Train and/or Val Folder Already Exists \\n')\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create Training Set\n",
    "for disease in (0, 1, 2, 3, 4):\n",
    "    path = '../SML_Project_Data/data/resized_' + str(disease)\n",
    "    \n",
    "    train_path = '../SML_Project_Data/data/train/resized_' + str(disease)\n",
    "    \n",
    "    val_path = '../SML_Project_Data/data/val/resized_' + str(disease)\n",
    "    \n",
    "    print('Looking to create folder of', path)\n",
    "    try:\n",
    "        os.mkdir(train_path)\n",
    "        os.mkdir(val_path)\n",
    "    except FileExistsError:\n",
    "        print('Train and/or Val Folder Already Exists \\n')\n",
    "    else:\n",
    "        # Copy first images to training set dir\n",
    "        fnames = ['{}.jpeg'.format(i) for i in range(train_file_count)]\n",
    "        for fname in fnames:\n",
    "            src = os.path.join(path, fname)\n",
    "            dst = os.path.join(train_path, fname)\n",
    "            shutil.copyfile(src, dst)\n",
    "        print('Moved files to ', train_path)\n",
    "\n",
    "        # Copy remainder to validation set\n",
    "        fnames = ['{}.jpeg'.format(i) for i in range(train_file_count, min_file_count)]\n",
    "        for fname in fnames:\n",
    "            src = os.path.join(path, fname)\n",
    "            dst = os.path.join(val_path, fname)\n",
    "            shutil.copyfile(src, dst)\n",
    "        print('Moved files to ', val_path)\n",
    "\n",
    "# Create Valiadtion Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Copy next 500 cat images to test_cats_dir\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy first 1000 dog images to train_dogs_dir\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy next 500 dog images to validation_dogs_dir\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy next 500 dog images to test_dogs_dir\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "1544_right.jpeg\n",
    "Upload failed\n",
    "1669_right.jpeg\n",
    "Upload failed\n",
    "2802_right.jpeg\n",
    "Upload failed\n",
    "4533_left.jpeg\n",
    "Upload failed\n",
    "4614_right.jpeg\n",
    "Upload failed\n",
    "4711_right.jpeg\n",
    "Upload failed\n",
    "4852_left.jpeg\n",
    "Upload failed\n",
    "4885_right.jpeg\n",
    "Upload failed\n",
    "6947_left.jpeg\n",
    "Upload failed\n",
    "9404_right.jpeg\n",
    "Upload failed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
