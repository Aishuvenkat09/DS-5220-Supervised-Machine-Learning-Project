{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation\n",
    "\n",
    "### Input:\n",
    "#### 1) CSV of Targets for each image\n",
    "#### 2) All folders of train images \n",
    "### Output:\n",
    "High level directory called data is created. Inside of high level folder are two major directories of Train and Val. Each major director has a seperate folder for each of the 5 classes\n",
    "### Next Steps:\n",
    "Move high level directory and all contents next to script which will train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3168, 4752, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load an color image in color\n",
    "img = cv2.imread('../SML_Project_Data/train/10_left.jpeg',1)\n",
    "print(img.shape)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to display image in window, results the kernel to die though.\n",
    "#cv2.imshow('image',img)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create PNG of Image Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('10_left_new.jpeg',img) # Confirmed manually the exported image is the correct size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Notes\n",
    "- Each eye can have a different disease value. However, there is strong correlation of the disease one eye to other eye\n",
    "- Images are different sizes, but it is easy to rescale all images to a set size\n",
    "- Colors have color, but not too much. Can try to convert to greyscale to reduce the bytes of the image which results in more room to have a larger image with more pixels. Note, this will require changing the model because it expects a size of (x, y, 3) of each of Red Green and Blue.\n",
    "- Classes are very unballanced with most being class 0. This must be solved before upload to system which trains model.\n",
    "- The Test data has no labels, so we should use the training data to evaluate the models\n",
    "- Each eye from a unique person has images next to each other in the training set\n",
    "- The JPEG are compressed versus RGB matrices, so they are smaller than those tensors by a factor of 15\n",
    "- If we use different format of the data, such as using a sick/healthy class this is done by changing the final layer of the CNN model as well as the Keras DirectoryIterator. This can be done by making sure that there are two folders inside of the train and val subfolder.\n",
    "# Code Notes\n",
    "- Keras CNN will run regardless of the input image size. However, would likely be best to alter internal structure depending upon input image size\n",
    "# Notes of Manual Steps\n",
    "- Ballancing the classes\n",
    "- Moving images into the proper folders of Google Colab\n",
    "# Next Steps\n",
    "See how to convert Keras code to use classification instead of binary! (Done)\n",
    "Use all data with a set target upload size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Image Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3168, 4752, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[1500][2300][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Size (3168, 4752, 3)\n",
      "45163008 bytes in original image\n",
      "MB in the original array image is 45.163008 versus the original image JPEG has 1.5 MB\n",
      "Resized Size (100, 100, 3)\n",
      "30000 bytes in compressed image\n",
      "Original pixel size is 45163008\n",
      "New pixel size is 30000\n",
      "Factor of reduction is by 1505.4336\n"
     ]
    }
   ],
   "source": [
    "print('Original Size', img.shape)\n",
    "\n",
    "print(\"%d bytes in original image\" % (img.size * img.itemsize))\n",
    "\n",
    "print('MB in the original array image is', img.size * img.itemsize / 1000000, 'versus the original image JPEG has 1.5 MB') # 1 million bytes in a MB\n",
    "\n",
    "resized = cv2.resize(img, (100, 100), interpolation = cv2.INTER_AREA)\n",
    "print('Resized Size', resized.shape)\n",
    "cv2.imwrite('10_left_reshaped_new.jpeg',resized) # Goes from 1.5 MB to 3 KB which redices the size by a factor 1 K\n",
    "\n",
    "print(\"%d bytes in compressed image\" % (resized.size * resized.itemsize))\n",
    "\n",
    "print('Original pixel size is', np.prod(img.shape))\n",
    "print('New pixel size is', np.prod(resized.shape))\n",
    "print('Factor of reduction is by', np.prod(img.shape) / np.prod(resized.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downscale Image to 100 x 100 x 3 and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35126\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image  level\n",
       "0   10_left      0\n",
       "1  10_right      0\n",
       "2   13_left      0\n",
       "3  13_right      0\n",
       "4   15_left      1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target = pd.read_csv('../SML_Project_Data/trainLabels.csv', delimiter=',')\n",
    "print(len(train_target))\n",
    "train_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8408"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_images = 0\n",
    "for index, row in train_target.iterrows():\n",
    "    split_image = row['image'].split('_')\n",
    "    image_num = split_image[0]\n",
    "    side = split_image[1]\n",
    "    \n",
    "    image_name = str(image_num) + '_' + side + '.jpeg'\n",
    "\n",
    "    train_image_path = '../SML_Project_Data/train/' + image_name\n",
    "\n",
    "    my_file = Path(train_image_path)\n",
    "\n",
    "    try:\n",
    "        my_abs_path = my_file.resolve(strict=True)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    else:\n",
    "        total_images = total_images + 1\n",
    "total_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351\n",
      "At 351 percent\n",
      "At 702 percent\n",
      "At 1053 percent\n",
      "At 1404 percent\n",
      "At 1755 percent\n",
      "At 2106 percent\n",
      "At 2457 percent\n",
      "At 2808 percent\n",
      "At 3159 percent\n",
      "At 3510 percent\n",
      "At 3861 percent\n",
      "At 4212 percent\n",
      "At 4563 percent\n",
      "At 4914 percent\n",
      "At 5265 percent\n",
      "At 5616 percent\n",
      "At 5967 percent\n",
      "At 6318 percent\n",
      "At 6669 percent\n",
      "At 7020 percent\n",
      "At 7371 percent\n",
      "At 7722 percent\n",
      "At 8073 percent\n",
      "Processed Imnage Count 8408\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "status = int(total_images / 20)\n",
    "print('Will give a status every', status, 'images')\n",
    "\n",
    "for index, row in train_target.iterrows():\n",
    "    #print(row['image'], row['level'])\n",
    "    \n",
    "    split_image = row['image'].split('_')\n",
    "    image_num = split_image[0]\n",
    "    side = split_image[1]\n",
    "\n",
    "    image_name = str(image_num) + '_' + side + '.jpeg'\n",
    "\n",
    "    train_image_path = '../SML_Project_Data/train/' + image_name\n",
    "\n",
    "    my_file = Path(train_image_path)\n",
    "\n",
    "    try:\n",
    "        my_abs_path = my_file.resolve(strict=True)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    else:\n",
    "        counter = counter + 1\n",
    "        \n",
    "        # Pull Image\n",
    "        img2 = cv2.imread(train_image_path, 1)\n",
    "        # Resize\n",
    "        resized = cv2.resize(img2, (100, 100), interpolation = cv2.INTER_AREA)\n",
    "        # Create New Image File\n",
    "        cv2.imwrite('../SML_Project_Data/resized_train/resized_train_' + str(row['level']) + '/' + image_name, resized)\n",
    "        resized\n",
    "    if counter % status == 0:\n",
    "        print('At', counter, 'images out of', total_images)\n",
    "        \n",
    "print('Processed Imnage Count', counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease Class of 0 has count of images of 6150\n",
      "Disease Class of 1 has count of images of 588\n",
      "Disease Class of 2 has count of images of 1283\n",
      "Disease Class of 3 has count of images of 221\n",
      "Disease Class of 4 has count of images of 166\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for disease_type in (0, 1, 2, 3, 4):\n",
    "    path, dirs, files = next(os.walk('../SML_Project_Data/resized_train/resized_train_' + str(disease_type)))\n",
    "    file_count = len(files)\n",
    "    print('Disease Class of', disease_type, 'has count of images of', file_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
