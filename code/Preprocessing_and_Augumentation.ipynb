{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augumentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More methods can be applied in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/1868714/how-do-i-copy-an-entire-directory-of-files-into-an-existing-directory-using-pyth/31039095\n",
    "from distutils.dir_util import copy_tree\n",
    "\n",
    "import random\n",
    "from scipy import ndarray\n",
    "import skimage as sk\n",
    "\n",
    "from skimage import transform\n",
    "from skimage import util\n",
    "from skimage import io\n",
    "from skimage.transform._warps_cy import _warp_fast\n",
    "from skimage.transform import SimilarityTransform\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creates Folders and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_data_folder = 'C:/Users/Aishwarya/Desktop/NEU/SML/project/SML_Project_Data'\n",
    "main_data_folder = '../SML_Project_Data'\n",
    "\n",
    "def clean_output_folders_augmentation(main_data_folder, disease_class, replace_folder = False):\n",
    "    '''Deletes existing folder in data/train and creates a few folder for a given disease class. Outputs names of input and output folder'''\n",
    "\n",
    "    downsized_data_path = main_data_folder + '/downsized_data'\n",
    "\n",
    "    folder_path = downsized_data_path + '/resized_' + str(disease_class)\n",
    "\n",
    "    print(folder_path)\n",
    "\n",
    "    training_folder = main_data_folder + '/data/train'\n",
    "    output_path = training_folder + '/resized_' + str(disease_class)\n",
    "\n",
    "    print(output_path)\n",
    "\n",
    "    if replace_folder:\n",
    "        try:\n",
    "            shutil.rmtree(output_path)\n",
    "        except FileNotFoundError:\n",
    "            os.mkdir(output_path)\n",
    "            print('Folder does not exist, it is created', output_path, '\\n')\n",
    "        else:\n",
    "            os.mkdir(output_path)\n",
    "            print('Deleting and creating the folder at', output_path, '\\n')\n",
    "    \n",
    "    return(folder_path, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counts number of files in each downsized_data_path folder to calculate target number of images to augment up to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease Class of 0 has count of images of 25668\n",
      "Disease Class of 1 has count of images of 2301\n",
      "Disease Class of 2 has count of images of 5150\n",
      "Disease Class of 3 has count of images of 731\n",
      "Disease Class of 4 has count of images of 566\n",
      "Maxinum count of training data to also use for augmentation 25668\n"
     ]
    }
   ],
   "source": [
    "downsized_data_path = main_data_folder + '/downsized_data'\n",
    "\n",
    "original_file_count = {0 : 0,\n",
    "                       1 : 0,\n",
    "                       2 : 0,\n",
    "                       3 : 0,\n",
    "                       4 : 0}\n",
    "\n",
    "max_file_count = 0\n",
    "for disease_type in (0, 1, 2, 3, 4):\n",
    "    path, dirs, files = next(os.walk(downsized_data_path + '/resized_' + str(disease_type)))\n",
    "    file_count = len(files)\n",
    "    if file_count > max_file_count:\n",
    "        max_file_count = file_count\n",
    "    print('Disease Class of', disease_type, 'has count of images of', file_count)\n",
    "    original_file_count\n",
    "    \n",
    "    original_file_count[disease_type]  =  file_count\n",
    "    \n",
    "print('Maxinum count of training data to also use for augmentation', max_file_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "## Function for Data Augmentation of One Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from skimage import img_as_ubyte\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "# our folder path containing some images\n",
    "#folder_path = 'C:/Users/Aishwarya/Desktop/NEU/SML/project/data/resized_1'\n",
    "\n",
    "def data_augmentation(folder_path, output_path, original_file_count, disease_type, max_file_count):\n",
    "    '''Need a way to find the last image that was created to avoid recreating all images in the folder'''\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # Determining number of files already created\n",
    "    path, dirs, files = next(os.walk(output_path))\n",
    "    current_file_count = len(files)\n",
    "    max_num_augmented_file_created = 0\n",
    "    if current_file_count != 0:\n",
    "        for file in files:\n",
    "            number = file.split('_')\n",
    "            #print(number)\n",
    "            #number = int(number[-1].split('.')[0])\n",
    "            number = int(number[0])\n",
    "            if number > max_num_augmented_file_created:\n",
    "                max_num_augmented_file_created = number\n",
    "    print('Images will start after number of', max_num_augmented_file_created)\n",
    "    \n",
    "    final_id_files_desired = max_file_count - original_file_count.get(disease_type)\n",
    "\n",
    "    if final_id_files_desired != 0:\n",
    "        \n",
    "        num_files_desired = final_id_files_desired - max_num_augmented_file_created\n",
    "        \n",
    "        print('Will be creating', num_files_desired, 'images for class', str(disease_type))\n",
    "    \n",
    "        # loop on all files of the folder and build a list of files paths\n",
    "        images = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "        available_transformations = {\n",
    "            'rotate': random_rotation,\n",
    "            'horizontal_flip': horizontal_flip,\n",
    "            'vertical_flip':vertical_flip,\n",
    "            'random_brithness': random_brithness\n",
    "        }\n",
    "        num_generated_files = max_num_augmented_file_created\n",
    "        print('Images will start to be created at', max_num_augmented_file_created)\n",
    "        \n",
    "        while num_generated_files < final_id_files_desired:\n",
    "            # random image from the folder\n",
    "            image_path = random.choice(images)\n",
    "            # read image as an two dimensional array of pixels\n",
    "            try:\n",
    "                image_to_transform = sk.io.imread(image_path)\n",
    "            except ValueError:\n",
    "                print('Value error with image', image_path, 'skipping')\n",
    "            else:\n",
    "\n",
    "                # random num of transformation to apply\n",
    "                num_transformations_to_apply = random.randint(1, len(available_transformations))\n",
    "\n",
    "                num_transformations = 0\n",
    "                transformed_image = None\n",
    "                while num_transformations <= num_transformations_to_apply:\n",
    "                    # random transformation to apply for a single image\n",
    "                    key = random.choice(list(available_transformations))\n",
    "                    transformed_image = available_transformations[key](image_to_transform)\n",
    "                    num_transformations += 1\n",
    "                    #new_path = 'C:/Users/Aishwarya/Desktop/NEU/SML/project/data/resized_1/augmented_image_'+ str(num_generated_files) + '.jpeg'\n",
    "                    new_path = output_path + '/augmented_image_'+ str(num_generated_files) + '.jpeg'\n",
    "\n",
    "                # write image to the disk\n",
    "               \n",
    "                io.imsave(new_path,img_as_ubyte(transformed_image))\n",
    "                num_generated_files += 1\n",
    "        \n",
    "        print(num_files_desired, 'files created for class', str(disease_type))\n",
    "        print('Last image created is', new_path)\n",
    "        total_time = datetime.now() - start_time\n",
    "        print('To complete the script for this class took', total_time)\n",
    "\n",
    "    else:\n",
    "        print('Class of', str(disease_type), 'has the maxinum size of', max_file_count, 'already')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loops through each class for Data Augmentation\n",
    "- 1) Creates Empty Folders\n",
    "- 2) Data Augmentation and places in train folder\n",
    "- 3) Moves non-augmented data into train folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for disease_type in (0, 1, 2, 3, 4):\n",
    "    \n",
    "    folder_path, output_path = clean_output_folders_augmentation(\n",
    "        main_data_folder,\n",
    "        disease_class=disease_type,\n",
    "        replace_folder = False)\n",
    "    \n",
    "    data_augmentation(\n",
    "        folder_path=folder_path,\n",
    "        output_path=output_path,\n",
    "        original_file_count=original_file_count,\n",
    "        max_file_count=max_file_count,\n",
    "        disease_type = disease_type\n",
    "                     )\n",
    "    \n",
    "    resized_image_path = downsized_data_path + '/resized_' + str(disease_type)\n",
    "    print(resized_image_path)\n",
    "    copy_tree(resized_image_path, output_path)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Training Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train disease class of 0 has count of images of 25668\n",
      "Train disease class of 1 has count of images of 25668\n",
      "Train disease class of 2 has count of images of 25668\n",
      "Train disease class of 3 has count of images of 25668\n",
      "Train disease class of 4 has count of images of 25668\n"
     ]
    }
   ],
   "source": [
    "for disease_type in (0, 1, 2, 3, 4):\n",
    "    path, dirs, files = next(os.walk(main_data_folder + '/data/train/resized_' + str(disease_type)))\n",
    "    file_count = len(files)\n",
    "    print('Train disease class of', disease_type, 'has count of images of', file_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
