{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation\n",
    "\n",
    "### Input:\n",
    "##### 1) CSV of Targets for each image\n",
    "##### 2) All folders of train images from Kaggle in a new folder called train in a local only SML_Project_Data folder (38.1 GB total). The SML_Project_Data folder is in the same folder as the GitHub folder of DS-5220-Supervised-Machine-Learning-Project\n",
    "### Output:\n",
    "##### High level directory called data is created. Inside of high level folder are two major directories of train and val. Each major director has a seperate folder for each of the 5 classes. This results in 10 folders with resized images in them.\n",
    "### Next Steps:\n",
    "##### Move high level directory and all contents next to script which will train model. The script which trains the model can create all of the folders, even though they would be empty of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Main Folder of Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data_folder = '../SML_Project_Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of a Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3168, 4752, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load an color image in color\n",
    "img = cv2.imread( main_data_folder + '/train/10_left.jpeg',1)\n",
    "print(img.shape)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create PNG of Image Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('10_left_new.jpeg',img) # Confirmed manually the exported image is the same number of bytes as the original image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Image Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3168, 4752, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[1500][2300][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Size (3168, 4752, 3)\n",
      "45163008 bytes in original image\n",
      "MB in the original array image is 45.163008 versus the original image JPEG has 1.5 MB\n",
      "Resized Size (100, 100, 3)\n",
      "30000 bytes in compressed image\n",
      "Original pixel size is 45163008\n",
      "New pixel size is 30000\n",
      "Factor of reduction is by 1505.4336\n"
     ]
    }
   ],
   "source": [
    "print('Original Size', img.shape)\n",
    "\n",
    "print(\"%d bytes in original image\" % (img.size * img.itemsize))\n",
    "\n",
    "print('MB in the original array image is', img.size * img.itemsize / 1000000, 'versus the original image JPEG has 1.5 MB') # 1 million bytes in a MB\n",
    "\n",
    "resized = cv2.resize(img, (100, 100), interpolation = cv2.INTER_AREA)\n",
    "print('Resized Size', resized.shape)\n",
    "cv2.imwrite('10_left_reshaped_new.jpeg',resized) # Goes from 1.5 MB to 3 KB which redices the size by a factor 1 K\n",
    "\n",
    "print(\"%d bytes in compressed image\" % (resized.size * resized.itemsize))\n",
    "\n",
    "print('Original pixel size is', np.prod(img.shape))\n",
    "print('New pixel size is', np.prod(resized.shape))\n",
    "print('Factor of reduction is by', np.prod(img.shape) / np.prod(resized.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downscale Images to 100 x 100 x 3 and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35126\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image  level\n",
       "0   10_left      0\n",
       "1  10_right      0\n",
       "2   13_left      0\n",
       "3  13_right      0\n",
       "4   15_left      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target = pd.read_csv(main_data_folder + '/trainLabels.csv', delimiter=',')\n",
    "print(len(train_target))\n",
    "train_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35126"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_images = 0\n",
    "for index, row in train_target.iterrows():\n",
    "    split_image = row['image'].split('_')\n",
    "    image_num = split_image[0]\n",
    "    side = split_image[1]\n",
    "    \n",
    "    image_name = str(image_num) + '_' + side + '.jpeg'\n",
    "\n",
    "    train_image_path = main_data_folder + '/train/' + image_name\n",
    "\n",
    "    my_file = Path(train_image_path)\n",
    "\n",
    "    try:\n",
    "        my_abs_path = my_file.resolve(strict=True)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    else:\n",
    "        total_images = total_images + 1\n",
    "total_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsizes all images and moves to subfolders in the main Data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Folder Already Exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create folders for each\n",
    "downsized_data_path = main_data_folder + '/downsized_data'\n",
    "try:\n",
    "    os.mkdir(downsized_data_path)\n",
    "except FileExistsError:\n",
    "    print('Data Folder Already Exists \\n')\n",
    "else:\n",
    "    print('Creating Data Folder \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking to create folder of ../SML_Project_Data/downsized_data/resized_0\n",
      "Folder Already Exists \n",
      "\n",
      "Looking to create folder of ../SML_Project_Data/downsized_data/resized_1\n",
      "Folder Already Exists \n",
      "\n",
      "Looking to create folder of ../SML_Project_Data/downsized_data/resized_2\n",
      "Folder Already Exists \n",
      "\n",
      "Looking to create folder of ../SML_Project_Data/downsized_data/resized_3\n",
      "Folder Already Exists \n",
      "\n",
      "Looking to create folder of ../SML_Project_Data/downsized_data/resized_4\n",
      "Folder Already Exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for disease in (0, 1, 2, 3, 4):\n",
    "    path = downsized_data_path + '/resized_' + str(disease)\n",
    "    print('Looking to create folder of', path)\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except FileExistsError:\n",
    "        print('Folder Already Exists \\n')\n",
    "    else:\n",
    "        print('Creating Folder \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsizing\n",
    "All images in Train folder and moving images to different folders inside of downsized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will give a status every 1756 images\n",
      "At 1756 images out of 35126\n",
      "At 3512 images out of 35126\n",
      "At 5268 images out of 35126\n",
      "At 7024 images out of 35126\n",
      "At 8780 images out of 35126\n",
      "At 10536 images out of 35126\n",
      "At 12292 images out of 35126\n",
      "At 14048 images out of 35126\n",
      "At 15804 images out of 35126\n",
      "At 17560 images out of 35126\n",
      "At 19316 images out of 35126\n",
      "At 21072 images out of 35126\n",
      "At 22828 images out of 35126\n",
      "At 24584 images out of 35126\n",
      "At 26340 images out of 35126\n",
      "At 28096 images out of 35126\n",
      "At 29852 images out of 35126\n",
      "At 31608 images out of 35126\n",
      "At 33364 images out of 35126\n",
      "At 35120 images out of 35126\n",
      "Processed Imnage Count 35126\n"
     ]
    }
   ],
   "source": [
    "# Distribute Images to each Folder\n",
    "counter = 0\n",
    "\n",
    "status = int(total_images / 20)\n",
    "print('Will give a status every', status, 'images')\n",
    "\n",
    "new_shape = (500, 500)\n",
    "\n",
    "for index, row in train_target.iterrows():\n",
    "    #print(row['image'], row['level'])\n",
    "    \n",
    "    split_image = row['image'].split('_')\n",
    "    image_num = split_image[0]\n",
    "    side = split_image[1]\n",
    "\n",
    "    image_name = str(image_num) + '_' + side + '.jpeg'\n",
    "\n",
    "    train_image_path = main_data_folder + '/train/' + image_name\n",
    "\n",
    "    my_file = Path(train_image_path)\n",
    "\n",
    "    try:\n",
    "        my_abs_path = my_file.resolve(strict=True)\n",
    "    except FileNotFoundError:\n",
    "        print('File not found')\n",
    "        pass\n",
    "    else:\n",
    "        counter = counter + 1\n",
    "        \n",
    "        # Pull Image\n",
    "        img2 = cv2.imread(train_image_path, 1)\n",
    "        # Resize\n",
    "        resized = cv2.resize(img2, new_shape, interpolation = cv2.INTER_AREA)\n",
    "        # Create New Image File\n",
    "        path = downsized_data_path + '/resized_' + str(row['level']) + '/' + image_name\n",
    "        #print('Path:', path)\n",
    "        cv2.imwrite(path, resized)\n",
    "        resized\n",
    "    if counter % status == 0:\n",
    "        print('At', counter, 'images out of', total_images)\n",
    "        \n",
    "print('Processed Imnage Count', counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting Downsized Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease Class of 0 has count of images of 25811\n",
      "Disease Class of 1 has count of images of 2444\n",
      "Disease Class of 2 has count of images of 5292\n",
      "Disease Class of 3 has count of images of 873\n",
      "Disease Class of 4 has count of images of 708\n",
      "Mininum count by class is 708\n",
      "Training set will have 566\n",
      "Validation/Test set will have 142\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os, shutil\n",
    "\n",
    "min_file_count = np.inf\n",
    "for disease_type in (0, 1, 2, 3, 4):\n",
    "    path, dirs, files = next(os.walk(downsized_data_path + '/resized_' + str(disease_type)))\n",
    "    file_count = len(files)\n",
    "    if file_count < min_file_count:\n",
    "        min_file_count = file_count\n",
    "    print('Disease Class of', disease_type, 'has count of images of', file_count)\n",
    "print('Mininum count by class is', min_file_count)\n",
    "    \n",
    "train_file_count = int(min_file_count * .80)\n",
    "print('Training set will have', train_file_count)\n",
    "val_file_count = min_file_count - train_file_count\n",
    "print('Validation/Test set will have', val_file_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Folders for Training and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../SML_Project_Data'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and/or Val Folder Already Exists \n",
      "\n",
      "Looking to create folders of resized_0\n",
      "Train Folder Already Exists in resized_0\n",
      "\n",
      "Looking to create folders of resized_1\n",
      "Train Folder Already Exists in resized_1\n",
      "\n",
      "Looking to create folders of resized_2\n",
      "Train Folder Already Exists in resized_2\n",
      "\n",
      "Looking to create folders of resized_3\n",
      "Train Folder Already Exists in resized_3\n",
      "\n",
      "Looking to create folders of resized_4\n",
      "Train Folder Already Exists in resized_4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(main_data_folder + '/data/train')\n",
    "    os.mkdir(main_data_folder + '/data/val')\n",
    "except FileExistsError:\n",
    "    print('Train and/or Val Folder Already Exists \\n')\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# Create Training Set\n",
    "for disease in (0, 1, 2, 3, 4):\n",
    "    path = 'resized_' + str(disease)\n",
    "    \n",
    "    train_path = main_data_folder + '/data/train/resized_' + str(disease)\n",
    "    \n",
    "    val_path = main_data_folder + '/data/val/resized_' + str(disease)\n",
    "    \n",
    "    print('Looking to create folders of', path)\n",
    "    try:\n",
    "        os.mkdir(train_path)\n",
    "    except FileExistsError:\n",
    "        print('Train Folder Already Exists in ' + path)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(val_path)\n",
    "    except FileExistsError:\n",
    "        print('Val Folder Already Exists in ' + path)\n",
    "    else:\n",
    "        pass\n",
    "            \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move Data from downsized_data to a validate Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         image  level\n",
      "0  33008_right      0\n",
      "1   20325_left      0\n",
      "2  21262_right      0\n",
      "3  32291_right      0\n",
      "4   29321_left      0\n",
      "Processed Image Count 710\n",
      "{0: 142, 1: 142, 2: 142, 3: 142, 4: 142} 0\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "track ={\n",
    "    0 : 0,\n",
    "    1 : 0,\n",
    "    2 : 0,\n",
    "    3 : 0,\n",
    "    4 : 0\n",
    "    }\n",
    "missing = 0\n",
    "\n",
    "# https://stackoverflow.com/questions/29576430/shuffle-dataframe-rows\n",
    "train_target_shuffled = train_target.sample(frac=1, random_state = 14).reset_index(drop=True)\n",
    "print(train_target_shuffled.head())\n",
    "\n",
    "for index, row in train_target_shuffled.iterrows():\n",
    "    #print(row['image'], row['level'])\n",
    "    \n",
    "    split_image = row['image'].split('_')\n",
    "    image_num = split_image[0]\n",
    "    side = split_image[1]\n",
    "\n",
    "    image_name = str(image_num) + '_' + side + '.jpeg'\n",
    "    #print(image_name)\n",
    "    \n",
    "    #train_image_path = main_data_folder + '/train/' + image_name\n",
    "\n",
    "    my_file = Path(train_image_path)\n",
    "\n",
    "    try:\n",
    "        my_abs_path = my_file.resolve(strict=True)\n",
    "    except FileNotFoundError:\n",
    "        #print('File not found')\n",
    "        pass\n",
    "    else:\n",
    "        #print('File found')\n",
    "        \n",
    "        # Check that the class of interest isn't full\n",
    "        if track.get(row['level']) < val_file_count:\n",
    "            # Pull Image\n",
    "            #img2 = cv2.imread(train_image_path, 1)\n",
    "            # Resize\n",
    "            #resized = cv2.resize(img2, new_shape, interpolation = cv2.INTER_AREA)\n",
    "            # Create New Image File\n",
    "            resized_path = downsized_data_path + '/resized_' + str(row['level']) + '/' + image_name\n",
    "            #print('Path:', path)\n",
    "            #img2 = cv2.imread(path, 1)\n",
    "            \n",
    "            \n",
    "            #d = {1: \"one\", 2: \"three\"}\n",
    "            #d1 = {2: \"two\"}\n",
    "\n",
    "            # updates the value of key 2\n",
    "            #d.update(d1)\n",
    "            #print(d)\n",
    "\n",
    "            #d1 = {3: \"three\"}\n",
    "            new_value = track.get(row['level']) + 1\n",
    "            track.update({row['level'] : new_value})\n",
    "\n",
    "            output_path = main_data_folder + '/data/val/resized_' + str(row['level']) + '/' + image_name\n",
    "            #cv2.imwrite(path, img2)\n",
    "            if os.path.isfile(resized_path):\n",
    "                #print('File moved')\n",
    "                shutil.move(src=resized_path, dst=output_path)\n",
    "                #shutil.copyfile(src=resized_path, dst=output_path)\n",
    "                counter = counter + 1\n",
    "            else:\n",
    "                missing = missing + 1\n",
    "        #else:\n",
    "        #    print('Limit for image class met')\n",
    "        \n",
    "#    if counter % status == 0:\n",
    "#        print('At', counter, 'images out of', total_images)\n",
    "        \n",
    "print('Processed Image Count', counter)\n",
    "\n",
    "print(track, missing )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some unzipping errors to google colab 1\n",
    "1544_right.jpeg\n",
    "Upload failed\n",
    "1669_right.jpeg\n",
    "Upload failed\n",
    "2802_right.jpeg\n",
    "Upload failed\n",
    "4533_left.jpeg\n",
    "Upload failed\n",
    "4614_right.jpeg\n",
    "Upload failed\n",
    "4711_right.jpeg\n",
    "Upload failed\n",
    "4852_left.jpeg\n",
    "Upload failed\n",
    "4885_right.jpeg\n",
    "Upload failed\n",
    "6947_left.jpeg\n",
    "Upload failed\n",
    "9404_right.jpeg\n",
    "Upload failed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
