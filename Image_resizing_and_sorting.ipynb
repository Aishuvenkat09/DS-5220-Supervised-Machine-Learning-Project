{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation\n",
    "\n",
    "## Input:\n",
    "- main_data_folder path from this file which will hold all data outside of git. This path folder is in the same folder that holds the GitHub folder of Diabetic-Retinopathy-Detection\n",
    "\n",
    "##### Inside of main_data_folder there must be placed:\n",
    "- 1) CSV of Targets for each image\n",
    "- 2) train folder with all unzipped image data (38.1 GB total from all 5 train zipped files)\n",
    "\n",
    "## Output:\n",
    "- 1) downsized_data folder which includes 5 class folder that will be used for both training and future data augmentation. The images are 500 x 500 x 3 pixels each.\n",
    "- 2) data folder\n",
    "- 3) Inside of the data folder there is a val and train folder\n",
    "- 4) The val folder has 142 images for each class. The images are randomely sellected with 500 x 500 x 3 pixels each.\n",
    "- 5) The train folder is empty\n",
    "\n",
    "### Next Steps:\n",
    "- Augment data in the downsized_data and put all new training data in the train folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Main Folder of Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data_folder = '../SML_Project_Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of a Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3168, 4752, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load an color image in color\n",
    "img = cv2.imread( main_data_folder + '/train/10_left.jpeg',1)\n",
    "print(img.shape)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create PNG of Image Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('10_left_new.jpeg',img) # Confirmed manually the exported image is the same number of bytes as the original image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Image Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3168, 4752, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[1500][2300][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Size (3168, 4752, 3)\n",
      "45163008 bytes in original image\n",
      "MB in the original array image is 45.163008 versus the original image JPEG has 1.5 MB when the JPEG has comression versus a tensor\n",
      "\n",
      "Resized Size (500, 500, 3)\n",
      "750000 bytes in compressed image\n",
      "New pixel size is 750000\n",
      "Factor of reduction is by 60.217344\n",
      "To get 100 K or so images in total, this would be around 5 times the original data set or a factor of original set of 12.0434688\n",
      "Results in GB of augmented data of 4.1516278100874064\n"
     ]
    }
   ],
   "source": [
    "print('Original Size', img.shape)\n",
    "\n",
    "print(\"%d bytes in original image\" % (np.prod(img.shape)))\n",
    "\n",
    "print('MB in the original array image is', img.size * img.itemsize / 1000000, 'versus the original image JPEG has 1.5 MB when the JPEG has comression versus a tensor') # 1 million bytes in a MB\n",
    "\n",
    "resized = cv2.resize(img, (500, 500), interpolation = cv2.INTER_AREA)\n",
    "print('\\nResized Size', resized.shape)\n",
    "cv2.imwrite('10_left_reshaped_new.jpeg',resized) # Goes from 1.5 MB to 3 KB which redices the size by a factor 1 K\n",
    "\n",
    "print(\"%d bytes in compressed image\" % (resized.size * resized.itemsize))\n",
    "\n",
    "print('New pixel size is', np.prod(resized.shape))\n",
    "print('Factor of reduction is by', np.prod(img.shape) / np.prod(resized.shape))\n",
    "\n",
    "print('To get 100 K or so images in total, this would be around 5 times the original data set or a factor of original set of', np.prod(img.shape) / (np.prod(resized.shape) * 5 ) )\n",
    "print('Results in GB of augmented data of', 50 / (np.prod(img.shape) / (np.prod(resized.shape) * 5 )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downscale Images to 500 x 500 x 3 and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35126\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image  level\n",
       "0   10_left      0\n",
       "1  10_right      0\n",
       "2   13_left      0\n",
       "3  13_right      0\n",
       "4   15_left      1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target = pd.read_csv(main_data_folder + '/trainLabels.csv', delimiter=',')\n",
    "print(len(train_target))\n",
    "train_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35126"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_images = 0\n",
    "for index, row in train_target.iterrows():\n",
    "    split_image = row['image'].split('_')\n",
    "    image_num = split_image[0]\n",
    "    side = split_image[1]\n",
    "    \n",
    "    image_name = str(image_num) + '_' + side + '.jpeg'\n",
    "\n",
    "    train_image_path = main_data_folder + '/train/' + image_name\n",
    "\n",
    "    my_file = Path(train_image_path)\n",
    "\n",
    "    try:\n",
    "        my_abs_path = my_file.resolve(strict=True)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    else:\n",
    "        total_images = total_images + 1\n",
    "total_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Folders to Store All Downsized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Folder Already Exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create folders for each\n",
    "downsized_data_path = main_data_folder + '/downsized_data'\n",
    "try:\n",
    "    os.mkdir(downsized_data_path)\n",
    "except FileExistsError:\n",
    "    print('Data Folder Already Exists \\n')\n",
    "else:\n",
    "    print('Creating Data Folder \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking to create folder of ../SML_Project_Data/downsized_data/resized_0\n",
      "Folder Already Exists \n",
      "\n",
      "Looking to create folder of ../SML_Project_Data/downsized_data/resized_1\n",
      "Folder Already Exists \n",
      "\n",
      "Looking to create folder of ../SML_Project_Data/downsized_data/resized_2\n",
      "Folder Already Exists \n",
      "\n",
      "Looking to create folder of ../SML_Project_Data/downsized_data/resized_3\n",
      "Folder Already Exists \n",
      "\n",
      "Looking to create folder of ../SML_Project_Data/downsized_data/resized_4\n",
      "Folder Already Exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for disease in (0, 1, 2, 3, 4):\n",
    "    path = downsized_data_path + '/resized_' + str(disease)\n",
    "    print('Looking to create folder of', path)\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except FileExistsError:\n",
    "        print('Folder Already Exists \\n')\n",
    "    else:\n",
    "        print('Creating Folder \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsizing\n",
    "All images in Train folder and moving images to different folders inside of downsized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will give a status every 1756 images\n",
      "At 1756 images out of 35126\n",
      "At 3512 images out of 35126\n",
      "At 5268 images out of 35126\n",
      "At 7024 images out of 35126\n",
      "At 8780 images out of 35126\n",
      "At 10536 images out of 35126\n",
      "At 12292 images out of 35126\n",
      "At 14048 images out of 35126\n",
      "At 15804 images out of 35126\n",
      "At 17560 images out of 35126\n",
      "At 19316 images out of 35126\n",
      "At 21072 images out of 35126\n",
      "At 22828 images out of 35126\n",
      "At 24584 images out of 35126\n",
      "At 26340 images out of 35126\n",
      "At 28096 images out of 35126\n",
      "At 29852 images out of 35126\n",
      "At 31608 images out of 35126\n",
      "At 33364 images out of 35126\n",
      "At 35120 images out of 35126\n",
      "Processed Imnage Count 35126\n"
     ]
    }
   ],
   "source": [
    "# Distribute Images to each Folder\n",
    "counter = 0\n",
    "\n",
    "status = int(total_images / 20)\n",
    "print('Will give a status every', status, 'images')\n",
    "\n",
    "new_shape = (500, 500)\n",
    "\n",
    "for index, row in train_target.iterrows():\n",
    "    #print(row['image'], row['level'])\n",
    "    \n",
    "    split_image = row['image'].split('_')\n",
    "    image_num = split_image[0]\n",
    "    side = split_image[1]\n",
    "\n",
    "    image_name = str(image_num) + '_' + side + '.jpeg'\n",
    "\n",
    "    train_image_path = main_data_folder + '/train/' + image_name\n",
    "\n",
    "    my_file = Path(train_image_path)\n",
    "\n",
    "    try:\n",
    "        my_abs_path = my_file.resolve(strict=True)\n",
    "    except FileNotFoundError:\n",
    "        print('File not found')\n",
    "        pass\n",
    "    else:\n",
    "        counter = counter + 1\n",
    "        \n",
    "        # Pull Image\n",
    "        img2 = cv2.imread(train_image_path, 1)\n",
    "        # Resize\n",
    "        resized = cv2.resize(img2, new_shape, interpolation = cv2.INTER_AREA)\n",
    "        # Create New Image File\n",
    "        path = downsized_data_path + '/resized_' + str(row['level']) + '/' + image_name\n",
    "        #print('Path:', path)\n",
    "        cv2.imwrite(path, resized)\n",
    "        resized\n",
    "    if counter % status == 0:\n",
    "        print('At', counter, 'images out of', total_images)\n",
    "        \n",
    "print('Processed Imnage Count', counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting Downsized Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease Class of 0 has count of images of 25810\n",
      "Disease Class of 1 has count of images of 2443\n",
      "Disease Class of 2 has count of images of 5292\n",
      "Disease Class of 3 has count of images of 873\n",
      "Disease Class of 4 has count of images of 708\n",
      "Mininum count by class is 708\n",
      "Training set will have 566\n",
      "Validation/Test set will have 142\n",
      "In Total there are 35126 images in downsized_data folder\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os, shutil\n",
    "\n",
    "total = 0\n",
    "min_file_count = np.inf\n",
    "for disease_type in (0, 1, 2, 3, 4):\n",
    "    path, dirs, files = next(os.walk(downsized_data_path + '/resized_' + str(disease_type)))\n",
    "    file_count = len(files)\n",
    "    if file_count < min_file_count:\n",
    "        min_file_count = file_count\n",
    "    print('Disease Class of', disease_type, 'has count of images of', file_count)\n",
    "    total = total + file_count\n",
    "print('Mininum count by class is', min_file_count)\n",
    "    \n",
    "train_file_count = int(min_file_count * .80)\n",
    "print('Training set will have', train_file_count)\n",
    "val_file_count = min_file_count - train_file_count\n",
    "print('Validation/Test set will have', val_file_count)\n",
    "\n",
    "print('In Total there are', total, 'images in downsized_data folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Folders for Training and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../SML_Project_Data'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and/or Val Folder Already Exists \n",
      "\n",
      "Looking to create folders of resized_0\n",
      "Train Folder Already Exists in resized_0\n",
      "Val Folder Already Exists in resized_0\n",
      "\n",
      "Looking to create folders of resized_1\n",
      "Train Folder Already Exists in resized_1\n",
      "Val Folder Already Exists in resized_1\n",
      "\n",
      "Looking to create folders of resized_2\n",
      "Train Folder Already Exists in resized_2\n",
      "Val Folder Already Exists in resized_2\n",
      "\n",
      "Looking to create folders of resized_3\n",
      "Train Folder Already Exists in resized_3\n",
      "Val Folder Already Exists in resized_3\n",
      "\n",
      "Looking to create folders of resized_4\n",
      "Train Folder Already Exists in resized_4\n",
      "Val Folder Already Exists in resized_4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(main_data_folder + '/data/train')\n",
    "    os.mkdir(main_data_folder + '/data/val')\n",
    "except FileExistsError:\n",
    "    print('Train and/or Val Folder Already Exists \\n')\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# Create Training Set\n",
    "for disease in (0, 1, 2, 3, 4):\n",
    "    path = 'resized_' + str(disease)\n",
    "    \n",
    "    train_path = main_data_folder + '/data/train/resized_' + str(disease)\n",
    "    \n",
    "    val_path = main_data_folder + '/data/val/resized_' + str(disease)\n",
    "    \n",
    "    print('Looking to create folders of', path)\n",
    "    try:\n",
    "        os.mkdir(train_path)\n",
    "    except FileExistsError:\n",
    "        print('Train Folder Already Exists in ' + path)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(val_path)\n",
    "    except FileExistsError:\n",
    "        print('Val Folder Already Exists in ' + path)\n",
    "    else:\n",
    "        pass\n",
    "            \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move 20% of Min Class Data from downsized_data to a validate Folder\n",
    "## Randomize train_target object, but keep sample individual next to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>level</th>\n",
       "      <th>id</th>\n",
       "      <th>side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33812_left</td>\n",
       "      <td>2</td>\n",
       "      <td>33812</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33812_right</td>\n",
       "      <td>4</td>\n",
       "      <td>33812</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40817_left</td>\n",
       "      <td>2</td>\n",
       "      <td>40817</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40817_right</td>\n",
       "      <td>2</td>\n",
       "      <td>40817</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26697_left</td>\n",
       "      <td>0</td>\n",
       "      <td>26697</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image  level     id   side\n",
       "0   33812_left      2  33812   left\n",
       "1  33812_right      4  33812  right\n",
       "2   40817_left      2  40817   left\n",
       "3  40817_right      2  40817  right\n",
       "4   26697_left      0  26697   left"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "train_target = pd.read_csv(main_data_folder + '/trainLabels.csv', delimiter=',')\n",
    "\n",
    "train_target[['id','side']] = train_target['image'].str.split(pat = \"_\", expand=True)\n",
    "\n",
    "groups = [train_target for _, train_target in train_target.groupby('id')]\n",
    "\n",
    "random.shuffle(groups)\n",
    "\n",
    "train_target = pd.concat(groups).reset_index(drop=True)\n",
    "train_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33812_left</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33812_right</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40817_left</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40817_right</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26697_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image  level\n",
       "0   33812_left      2\n",
       "1  33812_right      4\n",
       "2   40817_left      2\n",
       "3  40817_right      2\n",
       "4   26697_left      0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.drop(['id', 'side'], axis=1, inplace = True)\n",
    "train_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move first records in each class to the validate folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Image Count 710\n",
      "{0: 142, 1: 142, 2: 142, 3: 142, 4: 142} 0\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "track ={\n",
    "    0 : 0,\n",
    "    1 : 0,\n",
    "    2 : 0,\n",
    "    3 : 0,\n",
    "    4 : 0\n",
    "    }\n",
    "missing = 0\n",
    "\n",
    "for index, row in train_target.iterrows():\n",
    "    #print(row['image'], row['level'])\n",
    "    \n",
    "    split_image = row['image'].split('_')\n",
    "    image_num = split_image[0]\n",
    "    side = split_image[1]\n",
    "\n",
    "    image_name = str(image_num) + '_' + side + '.jpeg'\n",
    "    #print(image_name)\n",
    "    \n",
    "    #train_image_path = main_data_folder + '/train/' + image_name\n",
    "\n",
    "    my_file = Path(train_image_path)\n",
    "\n",
    "    try:\n",
    "        my_abs_path = my_file.resolve(strict=True)\n",
    "    except FileNotFoundError:\n",
    "        #print('File not found')\n",
    "        pass\n",
    "    else:\n",
    "        #print('File found')\n",
    "        \n",
    "        # Check that the class of interest isn't full\n",
    "        if track.get(row['level']) < val_file_count:\n",
    "            # Create New Image File\n",
    "            resized_path = downsized_data_path + '/resized_' + str(row['level']) + '/' + image_name\n",
    "\n",
    "            #d1 = {3: \"three\"}\n",
    "            new_value = track.get(row['level']) + 1\n",
    "            track.update({row['level'] : new_value})\n",
    "\n",
    "            output_path = main_data_folder + '/data/val/resized_' + str(row['level']) + '/' + image_name\n",
    "            #cv2.imwrite(path, img2)\n",
    "            if os.path.isfile(resized_path):\n",
    "                #print('File moved')\n",
    "                shutil.move(src=resized_path, dst=output_path)\n",
    "                #shutil.copyfile(src=resized_path, dst=output_path)\n",
    "                counter = counter + 1\n",
    "            else:\n",
    "                missing = missing + 1\n",
    "        \n",
    "print('Processed Image Count', counter)\n",
    "\n",
    "print(track, missing )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy Images from Validate back to downsized_data Folder (When Error in Validation Sellection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils.dir_util import copy_tree\n",
    "\n",
    "def move_back_downsized_data(main_data_folder, downsized_data_path, run = False):\n",
    "    if run:\n",
    "\n",
    "        for disease in (0, 1, 2, 3, 4):\n",
    "\n",
    "            # Validation File Path\n",
    "            val_path = main_data_folder + '/data/val/resized_' + str(disease)\n",
    "\n",
    "            # Downsized File Path\n",
    "            downsized_disease_path = downsized_data_path + '/resized_' + str(disease)\n",
    "\n",
    "            copy_tree(val_path, downsized_disease_path)\n",
    "    \n",
    "    else:\n",
    "        print('Setting of run is False, the validate images are NOT copied back to the downsized_data folder')\n",
    "            \n",
    "move_back_downsized_data(main_data_folder, downsized_data_path, run = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some unzipping errors to google colab 1\n",
    "1544_right.jpeg\n",
    "Upload failed\n",
    "1669_right.jpeg\n",
    "Upload failed\n",
    "2802_right.jpeg\n",
    "Upload failed\n",
    "4533_left.jpeg\n",
    "Upload failed\n",
    "4614_right.jpeg\n",
    "Upload failed\n",
    "4711_right.jpeg\n",
    "Upload failed\n",
    "4852_left.jpeg\n",
    "Upload failed\n",
    "4885_right.jpeg\n",
    "Upload failed\n",
    "6947_left.jpeg\n",
    "Upload failed\n",
    "9404_right.jpeg\n",
    "Upload failed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
