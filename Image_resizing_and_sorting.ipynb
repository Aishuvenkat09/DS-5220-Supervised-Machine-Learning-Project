{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation\n",
    "\n",
    "## Input:\n",
    "- main_data_folder path from this file which will hold all data outside of git. This path folder is in the same folder that holds the GitHub folder of Diabetic-Retinopathy-Detection\n",
    "\n",
    "##### Inside of main_data_folder there must be placed:\n",
    "- 1) CSV of Targets for each image\n",
    "- 2) train folder with all unzipped image data (38.1 GB total from all 5 train zipped files)\n",
    "\n",
    "## Output:\n",
    "- 1) downsized_data folder which includes 5 class folder that will be used for both training and future data augmentation. The images are 500 x 500 x 3 pixels each. The validate and test images are not in the folder.\n",
    "- 2) data folder\n",
    "- 3) Inside of the data folder there is a train, val, and test folder. The train folder is empty.\n",
    "- 4) The val & test folder each have 71 randomely selected images for each class. These folders does not contain images in the downsized_data folder.\n",
    "\n",
    "### Next Steps:\n",
    "- Augment data in the downsized_data and put all new training data in the train folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "from distutils.dir_util import copy_tree\n",
    "from pathlib import Path as path_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input\n",
    "- Main Folder of Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data_folder = '../SML_Project_Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of a Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3168, 4752, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load an color image in color\n",
    "img = cv2.imread( main_data_folder + '/train/10_left.jpeg',1)\n",
    "print(img.shape)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create PNG of Image Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('10_left_new.jpeg',img) # Confirmed manually the exported image is the same number of bytes as the original image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Image Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3168, 4752, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[1500][2300][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Size (3168, 4752, 3)\n",
      "45163008 bytes in original image\n",
      "MB in the original array image is 45.163008 versus the original image JPEG has 1.5 MB when the JPEG has comression versus a tensor\n",
      "\n",
      "Resized Size (500, 500, 3)\n",
      "750000 bytes in compressed image\n",
      "New pixel size is 750000\n",
      "Factor of reduction is by 60.217344\n",
      "To get 100 K or so images in total, this would be around 5 times the original data set or a factor of original set of 12.0434688\n",
      "Results in GB of augmented data of 4.1516278100874064\n"
     ]
    }
   ],
   "source": [
    "print('Original Size', img.shape)\n",
    "\n",
    "print(\"%d bytes in original image\" % (np.prod(img.shape)))\n",
    "\n",
    "print('MB in the original array image is', img.size * img.itemsize / 1000000, 'versus the original image JPEG has 1.5 MB when the JPEG has comression versus a tensor') # 1 million bytes in a MB\n",
    "\n",
    "resized = cv2.resize(img, (500, 500), interpolation = cv2.INTER_AREA)\n",
    "print('\\nResized Size', resized.shape)\n",
    "cv2.imwrite('10_left_reshaped_new.jpeg',resized) # Goes from 1.5 MB to 3 KB which redices the size by a factor 1 K\n",
    "\n",
    "print(\"%d bytes in compressed image\" % (resized.size * resized.itemsize))\n",
    "\n",
    "print('New pixel size is', np.prod(resized.shape))\n",
    "print('Factor of reduction is by', np.prod(img.shape) / np.prod(resized.shape))\n",
    "\n",
    "print('To get 100 K or so images in total, this would be around 5 times the original data set or a factor of original set of', np.prod(img.shape) / (np.prod(resized.shape) * 5 ) )\n",
    "print('Results in GB of augmented data of', 50 / (np.prod(img.shape) / (np.prod(resized.shape) * 5 )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downscale Images to 500 x 500 x 3 and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35126\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image  level\n",
       "0   10_left      0\n",
       "1  10_right      0\n",
       "2   13_left      0\n",
       "3  13_right      0\n",
       "4   15_left      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target = pd.read_csv(main_data_folder + '/trainLabels.csv', delimiter=',')\n",
    "print(len(train_target))\n",
    "train_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35126"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_images = 0\n",
    "for index, row in train_target.iterrows():\n",
    "    split_image = row['image'].split('_')\n",
    "    image_num = split_image[0]\n",
    "    side = split_image[1]\n",
    "    \n",
    "    image_name = str(image_num) + '_' + side + '.jpeg'\n",
    "\n",
    "    train_image_path = main_data_folder + '/train/' + image_name\n",
    "\n",
    "    my_file = Path(train_image_path)\n",
    "\n",
    "    try:\n",
    "        my_abs_path = my_file.resolve(strict=True)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    else:\n",
    "        total_images = total_images + 1\n",
    "total_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Folders to Store All Downsized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking to create folders of ../SML_Project_Data/downsized_data\n",
      "Folder Already Exists in ../SML_Project_Data/downsized_data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_folder(path, replace = False):\n",
    "    if replace:\n",
    "        print('Attempting to delete folder of', path)\n",
    "        try:\n",
    "            shutil.rmtree(path)\n",
    "        except FileNotFoundError:\n",
    "            print('Folder already does not exist')\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    print('Looking to create folders of', path)\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "        print('')\n",
    "    except FileExistsError:\n",
    "        print('Folder Already Exists in ' + path + '\\n')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# Create folders for each\n",
    "downsized_data_path = main_data_folder + '/downsized_data'\n",
    "\n",
    "create_folder(downsized_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking to create folders of ../SML_Project_Data/downsized_data/resized_0\n",
      "Folder Already Exists in ../SML_Project_Data/downsized_data/resized_0\n",
      "\n",
      "Looking to create folders of ../SML_Project_Data/downsized_data/resized_1\n",
      "Folder Already Exists in ../SML_Project_Data/downsized_data/resized_1\n",
      "\n",
      "Looking to create folders of ../SML_Project_Data/downsized_data/resized_2\n",
      "Folder Already Exists in ../SML_Project_Data/downsized_data/resized_2\n",
      "\n",
      "Looking to create folders of ../SML_Project_Data/downsized_data/resized_3\n",
      "Folder Already Exists in ../SML_Project_Data/downsized_data/resized_3\n",
      "\n",
      "Looking to create folders of ../SML_Project_Data/downsized_data/resized_4\n",
      "Folder Already Exists in ../SML_Project_Data/downsized_data/resized_4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for disease in (0, 1, 2, 3, 4):\n",
    "    path = downsized_data_path + '/resized_' + str(disease)\n",
    "    create_folder(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsizing\n",
    "All images in Train folder and moving images to different folders inside of downsized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will give a status every 1756 images\n",
      "At 1756 images out of 35126\n",
      "At 3512 images out of 35126\n",
      "At 5268 images out of 35126\n",
      "At 7024 images out of 35126\n",
      "At 8780 images out of 35126\n",
      "At 10536 images out of 35126\n",
      "At 12292 images out of 35126\n",
      "At 14048 images out of 35126\n",
      "At 15804 images out of 35126\n",
      "At 17560 images out of 35126\n",
      "At 19316 images out of 35126\n",
      "At 21072 images out of 35126\n",
      "At 22828 images out of 35126\n",
      "At 24584 images out of 35126\n",
      "At 26340 images out of 35126\n",
      "At 28096 images out of 35126\n",
      "At 29852 images out of 35126\n",
      "At 31608 images out of 35126\n",
      "At 33364 images out of 35126\n",
      "At 35120 images out of 35126\n",
      "Processed Imnage Count 35126\n"
     ]
    }
   ],
   "source": [
    "# Distribute Images to each Folder\n",
    "from datetime import datetime\n",
    "\n",
    "counter = 0\n",
    "\n",
    "status = int(total_images / 20)\n",
    "print('Will give a status every', status, 'images')\n",
    "\n",
    "new_shape = (500, 500)\n",
    "\n",
    "for index, row in train_target.iterrows():\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    split_image = row['image'].split('_')\n",
    "    image_num = split_image[0]\n",
    "    side = split_image[1]\n",
    "\n",
    "    image_name = str(image_num) + '_' + side + '.jpeg'\n",
    "\n",
    "    train_image_path = main_data_folder + '/train/' + image_name\n",
    "\n",
    "    my_file = Path(train_image_path)\n",
    "\n",
    "    try:\n",
    "        my_file.resolve(strict=True)\n",
    "    except FileNotFoundError:\n",
    "        print('File not found')\n",
    "        pass\n",
    "    else:\n",
    "        counter = counter + 1\n",
    "        \n",
    "        # Pull Image\n",
    "        img2 = cv2.imread(train_image_path, 1)\n",
    "        # Resize\n",
    "        resized = cv2.resize(img2, new_shape, interpolation = cv2.INTER_AREA)\n",
    "        # Create New Image File\n",
    "        path = downsized_data_path + '/resized_' + str(row['level']) + '/' + image_name\n",
    "        #print('Path:', path)\n",
    "        cv2.imwrite(path, resized)\n",
    "        resized\n",
    "    if counter % status == 0:\n",
    "        print('At', counter, 'images out of', total_images)\n",
    "        \n",
    "total_time = datetime.now() - start_time\n",
    "print('To complete the script for this class took', total_time)\n",
    "        \n",
    "print('Processed Imnage Count', counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting Downsized Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease Class of 0 has count of images of 25668\n",
      "Disease Class of 1 has count of images of 2301\n",
      "Disease Class of 2 has count of images of 5150\n",
      "Disease Class of 3 has count of images of 731\n",
      "Disease Class of 4 has count of images of 566\n",
      "Mininum count by class is 566\n",
      "Training set will have 452\n",
      "Validation & Test set will each have an image count of 57\n",
      "In Total there are 34416 images in downsized_data folder\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os, shutil\n",
    "\n",
    "total = 0\n",
    "min_file_count = np.inf\n",
    "for disease_type in (0, 1, 2, 3, 4):\n",
    "    path, dirs, files = next(os.walk(downsized_data_path + '/resized_' + str(disease_type)))\n",
    "    file_count = len(files)\n",
    "    if file_count < min_file_count:\n",
    "        min_file_count = file_count\n",
    "    print('Disease Class of', disease_type, 'has count of images of', file_count)\n",
    "    total = total + file_count\n",
    "print('Mininum count by class is', min_file_count)\n",
    "    \n",
    "train_file_count = int(min_file_count * .80)\n",
    "print('Training set will have', train_file_count)\n",
    "val_file_count = min_file_count - train_file_count\n",
    "print('Validation & Test set will each have an image count of', int(val_file_count/2))\n",
    "\n",
    "print('In Total there are', total, 'images in downsized_data folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Folders for Training, Validation and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../SML_Project_Data'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to delete folder of ../SML_Project_Data/data\n",
      "Looking to create folders of ../SML_Project_Data/data\n",
      "\n",
      "Attempting to delete folder of ../SML_Project_Data/data/train\n",
      "Folder already does not exist\n",
      "Looking to create folders of ../SML_Project_Data/data/train\n",
      "\n",
      "Attempting to delete folder of ../SML_Project_Data/data/val\n",
      "Folder already does not exist\n",
      "Looking to create folders of ../SML_Project_Data/data/val\n",
      "\n",
      "Attempting to delete folder of ../SML_Project_Data/data/test\n",
      "Folder already does not exist\n",
      "Looking to create folders of ../SML_Project_Data/data/test\n",
      "\n",
      "Attempting to delete folder of ../SML_Project_Data/data/train/resized_0\n",
      "Folder already does not exist\n",
      "Looking to create folders of ../SML_Project_Data/data/train/resized_0\n",
      "\n",
      "Attempting to delete folder of ../SML_Project_Data/data/val/resized_0\n",
      "Folder already does not exist\n",
      "Looking to create folders of ../SML_Project_Data/data/val/resized_0\n",
      "\n",
      "Attempting to delete folder of ../SML_Project_Data/data/test/resized_0\n",
      "Folder already does not exist\n",
      "Looking to create folders of ../SML_Project_Data/data/test/resized_0\n",
      "\n",
      "Attempting to delete folder of ../SML_Project_Data/data/train/resized_1\n",
      "Folder already does not exist\n",
      "Looking to create folders of ../SML_Project_Data/data/train/resized_1\n",
      "\n",
      "Attempting to delete folder of ../SML_Project_Data/data/val/resized_1\n",
      "Folder already does not exist\n",
      "Looking to create folders of ../SML_Project_Data/data/val/resized_1\n",
      "\n",
      "Attempting to delete folder of ../SML_Project_Data/data/test/resized_1\n",
      "Folder already does not exist\n",
      "Looking to create folders of ../SML_Project_Data/data/test/resized_1\n",
      "\n",
      "Attempting to delete folder of ../SML_Project_Data/data/train/resized_2\n",
      "Folder already does not exist\n",
      "Looking to create folders of ../SML_Project_Data/data/train/resized_2\n",
      "\n",
      "Attempting to delete folder of ../SML_Project_Data/data/val/resized_2\n",
      "Folder already does not exist\n",
      "Looking to create folders of ../SML_Project_Data/data/val/resized_2\n",
      "\n",
      "Attempting to delete folder of ../SML_Project_Data/data/test/resized_2\n",
      "Folder already does not exist\n",
      "Looking to create folders of ../SML_Project_Data/data/test/resized_2\n",
      "\n",
      "Attempting to delete folder of ../SML_Project_Data/data/train/resized_3\n",
      "Folder already does not exist\n",
      "Looking to create folders of ../SML_Project_Data/data/train/resized_3\n",
      "\n",
      "Attempting to delete folder of ../SML_Project_Data/data/val/resized_3\n",
      "Folder already does not exist\n",
      "Looking to create folders of ../SML_Project_Data/data/val/resized_3\n",
      "\n",
      "Attempting to delete folder of ../SML_Project_Data/data/test/resized_3\n",
      "Folder already does not exist\n",
      "Looking to create folders of ../SML_Project_Data/data/test/resized_3\n",
      "\n",
      "Attempting to delete folder of ../SML_Project_Data/data/train/resized_4\n",
      "Folder already does not exist\n",
      "Looking to create folders of ../SML_Project_Data/data/train/resized_4\n",
      "\n",
      "Attempting to delete folder of ../SML_Project_Data/data/val/resized_4\n",
      "Folder already does not exist\n",
      "Looking to create folders of ../SML_Project_Data/data/val/resized_4\n",
      "\n",
      "Attempting to delete folder of ../SML_Project_Data/data/test/resized_4\n",
      "Folder already does not exist\n",
      "Looking to create folders of ../SML_Project_Data/data/test/resized_4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_folder(main_data_folder + '/data', replace = True)\n",
    "create_folder(main_data_folder + '/data/train', replace = True)\n",
    "create_folder(main_data_folder + '/data/val', replace = True)\n",
    "create_folder(main_data_folder + '/data/test', replace = True)\n",
    "\n",
    "# Create Training Set\n",
    "for disease in (0, 1, 2, 3, 4):\n",
    "    for type_path in ('train','val','test'):\n",
    "        path = main_data_folder + '/data/' + type_path + '/resized_' + str(disease)\n",
    "        create_folder(path, replace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy all files from downsized_data_path to a saved folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_downsized_images = False\n",
    "\n",
    "if save_downsized_images:\n",
    "    print('Duplicating:' ,downsized_data_path)\n",
    "    path = downsized_data_path + '_saved'\n",
    "    print(path)\n",
    "\n",
    "    copy_tree(src=downsized_data_path, dst=path, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move 10% each of Min Class Data from downsized_data_path to val and test (20% total)\n",
    "## Randomize train_target object, but keep sample individual next to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>level</th>\n",
       "      <th>id</th>\n",
       "      <th>side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24779_left</td>\n",
       "      <td>2</td>\n",
       "      <td>24779</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24779_right</td>\n",
       "      <td>2</td>\n",
       "      <td>24779</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26490_left</td>\n",
       "      <td>0</td>\n",
       "      <td>26490</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26490_right</td>\n",
       "      <td>0</td>\n",
       "      <td>26490</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40232_left</td>\n",
       "      <td>2</td>\n",
       "      <td>40232</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image  level     id   side\n",
       "0   24779_left      2  24779   left\n",
       "1  24779_right      2  24779  right\n",
       "2   26490_left      0  26490   left\n",
       "3  26490_right      0  26490  right\n",
       "4   40232_left      2  40232   left"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "train_target = pd.read_csv(main_data_folder + '/trainLabels.csv', delimiter=',')\n",
    "\n",
    "train_target[['id','side']] = train_target['image'].str.split(pat = \"_\", expand=True)\n",
    "\n",
    "groups = [train_target for _, train_target in train_target.groupby('id')]\n",
    "\n",
    "random.Random(14).shuffle(groups)\n",
    "\n",
    "train_target = pd.concat(groups).reset_index(drop=True)\n",
    "train_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24779_left</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24779_right</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26490_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26490_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40232_left</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image  level\n",
       "0   24779_left      2\n",
       "1  24779_right      2\n",
       "2   26490_left      0\n",
       "3  26490_right      0\n",
       "4   40232_left      2"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.drop(['id', 'side'], axis=1, inplace = True)\n",
    "train_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move first records in each class to the validate folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Image Count 355\n",
      "{0: 71, 1: 71, 2: 71, 3: 71, 4: 71} Missing images are 0\n",
      "Processed Image Count 355\n",
      "{0: 71, 1: 71, 2: 71, 3: 71, 4: 71} Missing images are 355\n"
     ]
    }
   ],
   "source": [
    "def move_files_val_test(downsized_data_path,\n",
    "                        main_data_folder,\n",
    "                        subfolder,\n",
    "                        val_file_count,\n",
    "                        move = False,\n",
    "                       verbose = False):\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    track ={\n",
    "        0 : 0,\n",
    "        1 : 0,\n",
    "        2 : 0,\n",
    "        3 : 0,\n",
    "        4 : 0\n",
    "        }\n",
    "    missing = 0\n",
    "\n",
    "    if move == False:\n",
    "        print('Copying and not moving files')\n",
    "    \n",
    "    for index, row in train_target.iterrows():\n",
    "\n",
    "        # Get training set path of next image\n",
    "        split_image = row['image'].split('_')\n",
    "        image_num = split_image[0]\n",
    "        side = split_image[1]\n",
    "        image_name = str(image_num) + '_' + side + '.jpeg'\n",
    "        downsized_image_path = downsized_data_path + '/resized_' + str(row['level']) + '/' + image_name\n",
    "        \n",
    "        # Check that the class of interest isn't full\n",
    "        if track.get(row['level']) < int(val_file_count/2):\n",
    "            if verbose:\n",
    "                print('required images is not full')\n",
    "        \n",
    "            # Check if file exists\n",
    "            if path_check(downsized_image_path).is_file():\n",
    "\n",
    "                # Create new image file path\n",
    "                output_path = main_data_folder + '/data/' + subfolder + '/resized_' + str(row['level']) + '/' + image_name\n",
    "\n",
    "                if move:\n",
    "                    shutil.move(src=downsized_image_path, dst=output_path)\n",
    "                else:\n",
    "                    print('Moving image from', downsized_image_path, 'to', output_path)\n",
    "                    shutil.copyfile(src=downsized_image_path, dst=output_path)\n",
    "                counter = counter + 1\n",
    "\n",
    "                # update counter on folder\n",
    "                new_value = track.get(row['level']) + 1\n",
    "                track.update({row['level'] : new_value})\n",
    "            else:\n",
    "                missing = missing + 1\n",
    "\n",
    "    print('Processed Image Count', counter)\n",
    "\n",
    "    print(track, 'Missing images are', missing )\n",
    "\n",
    "for subfolder in ('val','test'):\n",
    "    move_files_val_test(downsized_data_path=downsized_data_path,\n",
    "                            main_data_folder=main_data_folder,\n",
    "                            subfolder=subfolder,\n",
    "                            val_file_count=val_file_count,\n",
    "                            move = True,\n",
    "                           verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If error, moves saved downsized images back to the downsized images folder.\n",
    "This will result in all images being in the folder again. This does not fun if error = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = False\n",
    "\n",
    "if error:\n",
    "    path = downsized_data_path + '_saved'\n",
    "    copy_tree(src=downsized_data_path + '_saved', dst=downsized_data_path, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilized to get comparison of no data augmentation or resampling with full data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_x_files_train(downsized_data_path,\n",
    "                        main_data_folder,\n",
    "                        subfolder,\n",
    "                        train_file_count=566,\n",
    "                        move = False,\n",
    "                       verbose = False):\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    track ={\n",
    "        0 : 0,\n",
    "        1 : 0,\n",
    "        2 : 0,\n",
    "        3 : 0,\n",
    "        4 : 0\n",
    "        }\n",
    "    missing = 0\n",
    "\n",
    "    if move == False:\n",
    "        print('Copying and not moving files')\n",
    "    \n",
    "    for index, row in train_target.iterrows():\n",
    "\n",
    "        # Get training set path of next image\n",
    "        split_image = row['image'].split('_')\n",
    "        image_num = split_image[0]\n",
    "        side = split_image[1]\n",
    "        image_name = str(image_num) + '_' + side + '.jpeg'\n",
    "        downsized_image_path = downsized_data_path + '/resized_' + str(row['level']) + '/' + image_name\n",
    "        if verbose:\n",
    "            print(downsized_image_path)\n",
    "        \n",
    "        # Check that the class of interest isn't full\n",
    "        if track.get(row['level']) < train_file_count:\n",
    "            if verbose:\n",
    "                print('required images is not full')\n",
    "        \n",
    "            # Check if file exists\n",
    "            if path_check(downsized_image_path).is_file():\n",
    "\n",
    "                # Create new image file path\n",
    "                output_path = main_data_folder + '/data/train/resized_' + str(row['level']) + '/' + image_name\n",
    "\n",
    "                if move:\n",
    "                    shutil.move(src=downsized_image_path, dst=output_path)\n",
    "                else:\n",
    "                    if verbose:\n",
    "                        print('Moving image from', downsized_image_path, 'to', output_path)\n",
    "                    shutil.copyfile(src=downsized_image_path, dst=output_path)\n",
    "                counter = counter + 1\n",
    "\n",
    "                # update counter on folder\n",
    "                new_value = track.get(row['level']) + 1\n",
    "                track.update({row['level'] : new_value})\n",
    "            else:\n",
    "                missing = missing + 1\n",
    "\n",
    "    print('Processed Image Count', counter)\n",
    "\n",
    "    print(track, 'Missing images are', missing )\n",
    "\n",
    "move_x_files_train(downsized_data_path=downsized_data_path,\n",
    "                        main_data_folder=main_data_folder,\n",
    "                        subfolder=subfolder,\n",
    "                        train_file_count=566,\n",
    "                        move = False,\n",
    "                       verbose = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
