{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imutils import paths\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "- 1. Select user\n",
    "- 2. Confirm main_data_folder holds the labeled excel sheet\n",
    "- 3. Confirm that root_folder contains a data folder which holds at least a train and validate folder\n",
    "- 4. Select if train PCA\n",
    "- 5. Select if train KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def directories_set(user):\n",
    "    if user == 'Aaron':\n",
    "        # Aaron\n",
    "        data_name = 'data_5000'\n",
    "        main_data_folder = '../SML_Project_Data'\n",
    "        root_folder= main_data_folder + '/' + data_name\n",
    "    elif user == 'Qiang':\n",
    "        # Qiang\n",
    "        data_name = 'data'\n",
    "        main_data_folder = 'D:/academic/DS 5220 Supervised Machine Learning/project/data'\n",
    "        root_folder='C:/Users/mjfun/Downloads/data'\n",
    "    elif user == 'Aishwara':\n",
    "        main_data_folder = 'C:/Users/Aishwarya/Desktop/NEU/SML/project'\n",
    "        root_folder = main_data_folder + '/data'\n",
    "        data_name = 'data'\n",
    "    else:\n",
    "        print('Unkown Users')\n",
    "        main_data_folder = None\n",
    "        root_folder = None\n",
    "        user = None\n",
    "        data_name = None\n",
    "        \n",
    "    return(main_data_folder, root_folder, user, data_name)\n",
    "\n",
    "main_data_folder, root_folder, user, data_name = directories_set('Qiang')\n",
    "\n",
    "train_pca = True\n",
    "train_knn = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image  level\n",
       "0   10_left      0\n",
       "1  10_right      0\n",
       "2   13_left      0\n",
       "3  13_right      0\n",
       "4   15_left      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(main_data_folder + '/trainLabels.csv',index_col=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image\n",
       "level       \n",
       "0      25810\n",
       "1       2443\n",
       "2       5292\n",
       "3        873\n",
       "4        708"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('level').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_feature_vector(image, size=(500, 500)):\n",
    "    # resize the image to a fixed size, then flatten the image into\n",
    "    # a list of raw pixel intensities\n",
    "    return cv2.resize(image, size).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_histogram(image, bins=(8, 8, 8)):\n",
    "    # extract a 3D color histogram from the HSV color space using\n",
    "    # the supplied number of `bins` per channel\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins,[0, 180, 0, 256, 0, 256])\n",
    "    # handle normalizing the histogram if we are using OpenCV 2.4.X\n",
    "    if imutils.is_cv2():\n",
    "        hist = cv2.normalize(hist)\n",
    "        # otherwise, perform \"in place\" normalization in OpenCV 3 (I# personally hate the way this is done\n",
    "    else:\n",
    "        cv2.normalize(hist, hist)\n",
    "        # return the flattened histogram as the feature vector\n",
    "    return hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the list of images that we'll be describing\n",
    "def create_list(root_folder, verbose = False, histogram = False):\n",
    "    if verbose:\n",
    "        print(\"[INFO] describing images...\")\n",
    "    # initialize the raw pixel intensities matrix, the features matrix, and labels list\n",
    "    rawImages = []\n",
    "    features = []\n",
    "    labels = []\n",
    "    for subfolder in next(os.walk(root_folder))[1]:\n",
    "        if verbose:\n",
    "            print(subfolder)\n",
    "        folder_path=root_folder+'/'+subfolder\n",
    "        if verbose:\n",
    "            print(folder_path)\n",
    "        imagePaths = list(paths.list_images(folder_path))\n",
    "        label=subfolder.split('_')[1]\n",
    "        # loop over the input images\n",
    "        for (i, imagePath) in enumerate(imagePaths):\n",
    "            # load the image\n",
    "            if verbose:\n",
    "                print(i,' read image: ',imagePath)\n",
    "            image = cv2.imread(imagePath)\n",
    "            #label = df[df['image']==imagePaths[i].split('\\\\')[1].split('.')[0]]['level'].values[0]\n",
    "            if verbose:\n",
    "                print(i,'label is: ',label)\n",
    "            # extract raw pixel intensity \"features\", followed by a color histogram to characterize the color distribution of the pixels in the image\n",
    "            if verbose:\n",
    "                print('start processing pixels.')\n",
    "            pixels = image_to_feature_vector(image)\n",
    "            if verbose:\n",
    "                print('start processing histogram')\n",
    "            if histogram:\n",
    "                hist = extract_color_histogram(image)\n",
    "            # update the raw images, features, and labels matricies,respectively\n",
    "            if verbose:\n",
    "                print('append list.')\n",
    "            rawImages.append(pixels)\n",
    "            \n",
    "            if histogram:\n",
    "                features.append(hist)\n",
    "            labels.append(label)\n",
    "        if histogram == False:\n",
    "            feature = None\n",
    "    return rawImages,features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data\n",
    "trainRI,trainFeat,trainLabels=create_list(root_folder + '/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validatioin data\n",
    "testRI,testFeat,testLabels=create_list(root_folder + '/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] pixels matrix: 18310.55MB\n",
      "[INFO] pixels matrix: 18.31GB\n"
     ]
    }
   ],
   "source": [
    "# show some information on the memory consumed by the raw images\n",
    "# matrix and features matrix\n",
    "arr_trainRI = np.array(trainRI)\n",
    "#arr_trainFeat = np.array(trainFeat)\n",
    "arr_trainLabels = np.array(trainLabels)\n",
    "print(\"[INFO] pixels matrix: {:.2f}MB\".format(arr_trainRI.nbytes / (1024 * 1000.0)))\n",
    "print(\"[INFO] pixels matrix: {:.2f}GB\".format(arr_trainRI.nbytes / (1024 * 1000.0 * 1000)))\n",
    "#print(\"[INFO] features matrix: {:.2f}MB\".format(arr_trainFeat.nbytes / (1024 * 1000.0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] pixels matrix: 520.02MB\n"
     ]
    }
   ],
   "source": [
    "arr_testRI = np.array(testRI)\n",
    "#arr_testFeat = np.array(testFeat)\n",
    "arr_testLabels = np.array(testLabels)\n",
    "print(\"[INFO] pixels matrix: {:.2f}MB\".format(arr_testRI.nbytes / (1024 * 1000.0)))\n",
    "#print(\"[INFO] features matrix: {:.2f}MB\".format(arr_testFeat.nbytes / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label\n",
       "label       \n",
       "0       5000\n",
       "1       5000\n",
       "2       5000\n",
       "3       5000\n",
       "4       5000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(arr_trainLabels,columns=['label']).groupby(pd.DataFrame(arr_trainLabels,columns=['label'])['label']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label\n",
       "label       \n",
       "0        142\n",
       "1        142\n",
       "2        142\n",
       "3        142\n",
       "4        142"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(testLabels,columns=['label']).groupby(pd.DataFrame(testLabels,columns=['label'])['label']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits, using 75%\n",
    "# of the data for training and the remaining 25% for testing\n",
    "#(trainRI, testRI, trainRL, testRL) = train_test_split(rawImages, labels, test_size=0.25, random_state=42)\n",
    "#(trainFeat, testFeat, trainLabels, testLabels) = train_test_split(features, labels, test_size=0.25, random_state=42)\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn import model_selection\n",
    "import pickle\n",
    "filename = 'pca_model_' + data_name + '.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Start getting PCA 2019-11-23 13:44:10.574785\n"
     ]
    }
   ],
   "source": [
    "# Training PCA model, takes around 30 minutes\n",
    "if train_pca:\n",
    "    start_time = datetime.now()\n",
    "    print(\"[INFO] Start getting PCA\", start_time)\n",
    "    pca_train = PCA(n_components=500)\n",
    "    pca_train.fit(trainRI)\n",
    "\n",
    "    pickle.dump(pca_train, open(filename, 'wb'))\n",
    "\n",
    "    print(\"[INFO] PCA model is made after\", datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "pca_train = pickle.load(open(filename, 'rb'))\n",
    "print(pca_train)\n",
    "\n",
    "pca_train_result = pca_train.transform(X=trainRI)\n",
    "pca_test_result = pca_train.transform(X=testRI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def calculate_accuracy(actual, predicted):\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for item in range(0, len(predicted)):\n",
    "        if actual[item] == predicted[item]:\n",
    "            correct = correct + 1\n",
    "        else:\n",
    "            incorrect = incorrect + 1\n",
    "    print('Accuracy is', correct / (correct + incorrect) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "print(\"[INFO] evaluating model accuracy after\", datetime.now() - start_time)\n",
    "model_logistic = LogisticRegression(n_jobs=8, verbose = 1, random_state=0, solver ='sag')# solver = 'lbfgs'\n",
    "print(\"[INFO] compiling fit\")\n",
    "model_logistic.fit(pca_train_result, trainLabels)\n",
    "print(\"[INFO] calculating accuracy\")\n",
    "predicted = model_logistic.predict(pca_train_result)\n",
    "\n",
    "print('Training Results:')\n",
    "calculate_accuracy(trainLabels, predicted)\n",
    "\n",
    "predicted = model_logistic.predict(pca_test_result)\n",
    "print('Test Results:')\n",
    "calculate_accuracy(testLabels, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating raw pixel accuracy at\n",
      "[INFO] compiling fit\n",
      "[INFO] calculating accuracy\n",
      "[INFO] raw pixel accuracy: 22.96%\n",
      "[INFO] scipt completing at 2019-11-17 15:48:55.251440 script took 0:01:59.372027\n"
     ]
    }
   ],
   "source": [
    "#Training on non-pca\n",
    "if train_knn:\n",
    "    # train and evaluate a k-NN classifer on the raw pixel intensities\n",
    "    start_time = datetime.now()\n",
    "    print(\"[INFO] evaluating raw pixel accuracy at\", start_time)\n",
    "    model_raw = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "    print(\"[INFO] compiling fit\")\n",
    "    model_raw.fit(trainRI, trainLabels)\n",
    "    print(\"[INFO] calculating accuracy\")\n",
    "    acc_raw = model_raw.score(testRI, testLabels)\n",
    "    end_time = datetime.now()\n",
    "    print(\"[INFO] raw pixel accuracy: {:.2f}%\".format(acc_raw * 100))\n",
    "    print(\"[INFO] scipt completing at\", end_time, \"script took\", end_time - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating histogram accuracy...\n",
      "[INFO] histogram accuracy: 22.25%\n"
     ]
    }
   ],
   "source": [
    "if train_knn:\n",
    "    # train and evaluate a k-NN classifer on the histogram\n",
    "    # representations\n",
    "    print(\"[INFO] evaluating histogram accuracy...\")\n",
    "    model_histogram = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "    model_histogram.fit(trainFeat, trainLabels)\n",
    "    acc_histogram = model_histogram.score(testFeat, testLabels)\n",
    "    print(\"[INFO] histogram accuracy: {:.2f}%\".format(acc_histogram * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2830 0\n",
      "Accuracy is 1.0\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "rfc=RandomForestClassifier(n_estimators=50)\n",
    "rfc.fit(pca_train_result, trainLabels)\n",
    "\n",
    "print('Random Forest Train Accuracy')\n",
    "y_pred=rfc.predict(pca_train_result)\n",
    "calculate_error(actual=trainLabels, predicted=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] scipt completing at 2019-11-22 23:17:52.991492 script took in total 0:00:09.633491\n",
      "145 565\n",
      "Accuracy is 0.20422535211267606\n"
     ]
    }
   ],
   "source": [
    "y_pred=rfc.predict(pca_test_result)\n",
    "print('Random Forest Test Accuracy')\n",
    "calculate_error(actual=testLabels, predicted=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
